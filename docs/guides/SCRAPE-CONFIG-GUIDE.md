# 网页爬虫配置功能使用指南

## 功能概述

网页爬虫系统采用**多策略智能提取**技术,自动尝试多种方法从网页中提取文章链接。当采集到错误的链接时(例如采集到了作者页、分类页而不是文章页),可以通过配置过滤规则来解决。

### 多策略提取

系统会按以下优先级尝试三种提取策略:

1. **标题链接提取** (`heading-link`)
   - 从 `<h1>`, `<h2>`, `<h3>` 标签中的链接提取
   - 适用于标准博客和新闻网站
   - 最精准,优先使用

2. **通用链接提取** (`generic-link`)
   - 从所有 `<a>` 标签中提取有意义的链接
   - 自动过滤导航、锚点、资源文件等
   - 当策略1找到的文章少于5篇时启用

3. **文章容器提取** (`article-container`)
   - 从带有 `post`, `article`, `entry`, `item`, `card` 等类名的容器中提取
   - 适用于使用特定 CSS 类名的现代网站
   - 当策略2仍找不到足够文章时启用

系统会在测试结果中显示使用的提取策略,帮助您了解采集情况。

## 问题示例

**场景**: 
- 目标URL: `https://www.therundown.ai/`
- 期望: 采集文章页面
- 实际: 采集到了 `/authors` 页面

## 解决方案

### 方法1: 排除规则 (推荐)

**适用场景**: 知道哪些链接不需要

**步骤**:
1. 测试信息源,查看采集结果
2. 发现错误链接(如 `/authors`)  
3. 点击"⚙️ 配置采集规则"
4. 在"排除 URL 模式"中添加 `/authors`
5. 点击"保存并重新测试"

**效果**: 所有包含 `/authors` 的链接将被过滤掉

### 方法2: 包含规则

**适用场景**: 明确知道文章链接的特征

**步骤**:
1. 点击"⚙️ 配置采集规则"
2. 在"只包含 URL 模式"中添加 `/article/` 或 `/posts/`
3. 点击"保存并重新测试"

**效果**: 只保留包含 `/article/` 或 `/posts/` 的链接

### 方法3: 组合使用

**最佳实践**: 同时使用排除和包含规则

```
排除规则:
- /authors
- /categories  
- /tags
- /about

包含规则:
- /article/
- /news/
```

## 完整流程示例

### 场景: 配置 Rundown AI 信息源

1. **首次测试**
   ```
   测试结果:
   ✓ 成功采集 6 篇文章
   
   文章列表:
   1. ✓ https://www.therundown.ai/article/123
   2. ❌ https://www.therundown.ai/authors/john
   3. ❌ https://www.therundown.ai/categories/ai
   4. ✓ https://www.therundown.ai/article/456
   ...
   ```

2. **发现问题**: 采集到了 `/authors` 和 `/categories` 页面

3. **添加配置**
   - 点击"⚙️ 配置采集规则"
   - 添加排除规则:
     * `/authors`
     * `/categories`
   - 点击"保存并重新测试"

4. **查看新结果**
   ```
   测试结果:
   ✅ 配置已应用
      成功过滤 2 个非文章链接
      采集到 4 篇有效文章
   
   文章列表:
   1. https://www.therundown.ai/article/123
   2. https://www.therundown.ai/article/456
   3. https://www.therundown.ai/article/789
   4. https://www.therundown.ai/article/012
   
   🚫 已过滤的链接:
   - https://www.therundown.ai/authors/john
   - https://www.therundown.ai/categories/ai
   ```

5. **确认并激活**
   - 确认采集结果正确
   - 点击"确认无误,返回激活"
   - 点击"激活"按钮

## 规则说明

### 排除规则

**格式**: URL中包含的文本

**示例**:
| 规则 | 效果 |
|------|------|
| `/authors` | 排除 `https://example.com/authors/john` |
| `/tag/` | 排除 `https://example.com/tag/ai` |
| `?page=` | 排除 `https://example.com/article?page=2` |

**注意**: 
- 规则是部分匹配,不是完全匹配
- 规则是大小写敏感的
- 可以添加多个规则

### 包含规则

**格式**: URL中必须包含的文本

**示例**:
| 规则 | 效果 |
|------|------|
| `/article/` | 只保留 `https://example.com/article/123` |
| `/posts/` | 只保留 `https://example.com/posts/456` |
| `/news/` | 只保留 `https://example.com/news/789` |

**注意**:
- 多个包含规则是"或"的关系(满足任意一个即可)
- 包含规则比排除规则优先级高

## 技术细节

### 规则应用顺序

1. **采集阶段**: 先采集所有链接(最多20个)
2. **排除过滤**: 应用排除规则
3. **包含过滤**: 应用包含规则  
4. **限制数量**: 取前10个

### 数据存储

配置保存在数据库的 `scrapeConfig` 字段:

```json
{
  "excludePatterns": ["/authors", "/categories"],
  "includePatterns": ["/article/", "/news/"]
}
```

### 自动重置

修改配置后会自动:
- 重置测试状态为"未测试"
- 停用信息源
- 需要重新测试并激活

## 无法提取文章的处理

如果测试后发现**完全没有采集到文章**或**采集数量极少**(少于3篇),可能的原因和解决方案:

### 原因1: 网站使用 JavaScript 动态加载内容

**症状**: 网页在浏览器中能看到内容,但爬虫采集不到

**解决方案**:
- 这类网站需要浏览器渲染才能获取内容
- 建议寻找该网站的 RSS 源
- 或联系管理员添加对该网站的特殊支持

### 原因2: 网站使用非标准 HTML 结构

**症状**: 网站结构特殊,不使用常见的 `<h1-3>` 或 `article` 容器

**解决方案**:
- 当前系统已支持三种提取策略
- 如果仍无法提取,建议优先寻找 RSS 源
- 也可以反馈给开发团队添加对特定网站的支持

### 原因3: 过滤规则过于严格

**症状**: 配置了包含规则后,文章数量大幅减少

**解决方案**:
- 检查包含规则是否过于具体
- 尝试放宽条件或只使用排除规则
- 清空所有规则重新测试

## 常见问题

### Q: 规则可以为空吗?

**A**: 可以!规则是可选的,留空表示不应用该类规则。

### Q: 排除规则和包含规则可以同时使用吗?

**A**: 可以!先应用排除规则,再应用包含规则。

### Q: 如何匹配多种文章格式?

**A**: 在包含规则中添加多个模式,例如:
```
/article/
/posts/
/news/
/blog/
```

### Q: 规则会影响RSS源吗?

**A**: 不会!"配置采集规则"按钮只对web类型的信息源显示。

### Q: 配置后需要重新激活吗?

**A**: 是的。修改配置后系统会自动停用该源,需要重新测试并激活。

## 最佳实践

1. **先测试,后配置**: 不要一开始就配置规则,先看看采集结果
2. **保守配置**: 从最明显的错误开始,逐步添加规则
3. **验证结果**: 每次配置后都要查看测试结果,确保没有误伤
4. **使用排除优先**: 排除规则通常比包含规则更安全
5. **定期检查**: 网站结构可能变化,定期重新测试

## 示例配置库

### Medium
```
排除: /tag/, /@, /latest
包含: /p/
```

### Dev.to
```
排除: /t/, /top, /latest  
包含: (留空,不需要)
```

### HashNode
```
排除: /newsletter, /series
包含: (留空,不需要)
```

---

**更新时间**: 2025-10-09
**版本**: 1.0.0
